{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TigerGraph GraphRAG for Document Question Answering\n",
    "\n",
    "This notebook demostrates how to use TigerGraph GraphRAG, an AI assistant for your TigerGraph databases. TigerGraph GraphRAG enables you to ask questions in natural language about your document data stored in TigerGraph and get answers in a human-readable format. GraphRAG is a graph-based retrieval-augmented generation approach that is used to answer questions about the document data stored in TigerGraph. TigerGraph GraphRAG is built to help users get started with GraphRAG and to provide a seamless experience for users to interact with their document data within TigerGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyTigerGraph import TigerGraphConnection\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# We first create a connection to the database\n",
    "host = \"http://localhost\" \n",
    "username = os.getenv(\"USERNAME\", \"tigergraph\")\n",
    "password = os.getenv(\"PASS\", \"tigergraph\")\n",
    "conn = TigerGraphConnection(\n",
    "    host=host,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    gsPort=\"14240\",\n",
    "    restppPort=\"14240\",\n",
    "    graphname = \"TigerGraphRAG\"\n",
    ")\n",
    "\n",
    "# And then add GraphRAG's address to the connection. This address\n",
    "# is the host's address where the GraphRAG container is running.\n",
    "conn.ai.configureGraphRAGHost(f\"{host}:8000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Graph and Ingest Data\n",
    "\n",
    "We provide utilities to setup your TigerGraph database with a schema and load your desired documents. In this example, we are utilizing the TigerGraph documentation as our dataset. The documents are processed into a JSONL file of the following format:\n",
    "\n",
    "```json\n",
    "{\"url\": \"some_url_here\", \"content\": \"Text of the document\"}\n",
    "```\n",
    "\n",
    "The following code block will create a graph called `TigerGraphRAG` and load the documents into the graph. The schema that is created looks like this:\n",
    "\n",
    "![graphrag_schema](../img/GraphRAGSchema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.gsql(f\"\"\"CREATE GRAPH {conn.graphname}()\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get connection token if authentication is enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to authenticate the connection\n",
    "conn.getToken()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create SuportAI schema and install related queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.ai.initializeSupportAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DocumentIngest for local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = conn.ai.createDocumentIngest(\n",
    "    data_source=\"local\",\n",
    "    data_source_config={\"data_path\": \"./data/tg_tutorials.jsonl\"},\n",
    "    loader_config={\"doc_id_field\": \"doc_id\", \"content_field\": \"content\", \"doc_type\": \"markdown\"},\n",
    "    file_format=\"json\",\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run DocumentIngest to load documents to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.ai.runDocumentIngest(res[\"load_job_id\"], res[\"data_source_id\"], res[\"data_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, create and run DocumentIngest for data files on Cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access = \"\"\n",
    "sec = \"\"\n",
    "res = conn.ai.createDocumentIngest(\n",
    "    data_source=\"s3\",\n",
    "    data_source_config={\"aws_access_key\": access, \"aws_secret_key\": sec},\n",
    "    loader_config={\"doc_id_field\": \"url\", \"content_field\": \"content\", \"doc_type\": \"\"},\n",
    "    file_format=\"json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.ai.runDocumentIngest(res[\"load_job_id\"], res[\"data_source_id\"], \"s3://tg-documentation/pytg_current/pytg_current.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Knowledge Graph from the documents loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.ai.forceConsistencyUpdate(\"graphrag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Document Search Methods\n",
    "\n",
    "TigerGraph GraphRAG provides multiple methods to search documents in the graph. The methods are:\n",
    "- **HNSW Overlap**: This method uses a combination of vector search and graph traversal to find the most relevant information to the query. It uses the HNSW algorithm to search the embeddings of documents, document chunks, entities, and relationships. These results serve as the starting point for the graph traversal. The graph traversal is used to find the most relevant information to the query.\n",
    "\n",
    "- **Vector Search**: This method uses the HNSW algorithm to search the embeddings of one of the document, document chunk, entity, or relationship vector indices. It returns the most relevant information to the query based on the embeddings. This method is what you would expect from a traditional vector RAG solution.\n",
    "\n",
    "- **Sibling Search**: This method is very similar to the Vector Search method, but it uses the sibling (IS_AFTER) relationships between document chunks to expand the context around the document chunk that is most relevant to the query. This method is useful when you want to get more context around the most relevant document chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I get the vertex count from TigerGrpah using Python?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HNSW Index Overlap in Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.ai.searchDocuments(query,\n",
    "                        method=\"hnswoverlap\",\n",
    "                        method_parameters = {\"indices\": [\"DocumentChunk\", \"Entity\"],\n",
    "                                             \"top_k\": 5,\n",
    "                                             \"num_hops\": 2,\n",
    "                                             \"num_seen_min\": 3,\n",
    "                                             \"verbose\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Chunk Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.ai.searchDocuments(query,\n",
    "                        method=\"vdb\",\n",
    "                        method_parameters={\"index\": \"DocumentChunk\",\n",
    "                                           \"top_k\": 5,\n",
    "                                           \"withHyDE\": False,\n",
    "                                           \"verbose\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sibling Document Chunk Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.ai.searchDocuments(query,\n",
    "                        method=\"sibling\",\n",
    "                        method_parameters={\"index\": \"DocumentChunk\",\n",
    "                                           \"top_k\": 5,\n",
    "                                           \"lookahead\": 3,\n",
    "                                           \"lookback\": 3,\n",
    "                                           \"withHyDE\": False,\n",
    "                                           \"verbose\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphRAG Document Chunk Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.ai.searchDocuments(query,\n",
    "                        method=\"graphrag\",\n",
    "                        method_parameters={\"community_level\": 2, \"top_k\": 3, \"verbose\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing LLM Generated Responses\n",
    "\n",
    "TigerGraph GraphRAG provides a way to generate the response to the user's query using a LLM, based on the search results from the methods above. You can compare the responses generated by the LLM for each of the search methods to see which one is the most relevant to the user's query. In this example, we can see that the HNSW Overlap method generates the most relevant response to the user's query. While none of the responses were wrong, the HNSW Overlap method generated the most relevant response to the user's query, by suggesting to use the `getVertexCount()` function to get the number of vertices in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = conn.ai.answerQuestion(query,\n",
    "                        method=\"graphrag\",\n",
    "                        method_parameters={\"community_level\": 2, \"top_k\": 3, \"verbose\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check verbose info for more details if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(resp[\"verbose\"], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer question using HNSW_Overlap Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = conn.ai.answerQuestion(query,\n",
    "                        method=\"hnswoverlap\",\n",
    "                        method_parameters = {\"indices\": [\"Document\", \"DocumentChunk\", \"Entity\", \"Relationship\"],\n",
    "                                             \"top_k\": 5,\n",
    "                                             \"num_hops\": 2,\n",
    "                                             \"num_seen_min\": 3,\n",
    "                                             \"verbose\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp[\"retrieved\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer question using HNSW similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = conn.ai.answerQuestion(query,\n",
    "                        method=\"vdb\",\n",
    "                        method_parameters={\"index\": \"DocumentChunk\",\n",
    "                                           \"top_k\": 5,\n",
    "                                           \"withHyDE\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer question using Sibling Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = conn.ai.answerQuestion(query,\n",
    "                        method=\"sibling\",\n",
    "                        method_parameters={\"index\": \"DocumentChunk\",\n",
    "                                           \"top_k\": 5,\n",
    "                                           \"lookahead\": 3,\n",
    "                                           \"lookback\": 3,\n",
    "                                           \"withHyDE\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp[\"response\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "copi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
